from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain.prompts import PromptTemplate
# from langchain_community.vectorstores import Pinecone
from pinecone import Pinecone
from langchain_openai import ChatOpenAI
import os
import json
from dotenv import load_dotenv

load_dotenv()

pinecone_api_key = os.getenv('PINECONE_API_KEY')
openai_api_key = os.getenv('OPENAI_API_KEY')

metadata_field_info = [
    AttributeInfo(
        name='Category',
        type='string',
        description='The category of the document chunk. Some examples are; Technical Details, Introduction, Overview, Contract, etc.'
    ),
    AttributeInfo(
        name='Keywords',
        type='list',
        description='Keywords associated with the document chunk. Some examples are; Voice and Data Radio System, INTRODUCTION, Configuration Management Tools, ECLRT, etc.'
    ),
    AttributeInfo(
        name='References',
        type='list',
        description='References to other documents or sections of the document chunk. Some examples are; Appendix G: Cyber Security Controls Verification Guidance, 2700-67ASA1-01-CTSC-0012_02.pdf, Cyber Security â€“ Change Control and Configuration Management Standard,5000-00-WGD-48PA-1020, etc.'
    ),
    AttributeInfo(
        name='Related Sections',
        type='list',
        description='References to other sections within the same document',
        ),
    AttributeInfo(
        name='Summary',
        type='string',
        description='Summary of chunk content, generated by the AI model',
        ),
    AttributeInfo(
        name='Authors',
        type='list',
        description='List of document authors',
        ),
    AttributeInfo(
        name='document_title',
        type='string',
        description='Document title',
        ),
    AttributeInfo(
        name='elementIDs',
        type='list',
        description='ids of the elements in the document chunk',
        ),
    AttributeInfo(
        name='filename',
        type='string',
        description='Name of the file the document chunk is from',
        ),
    AttributeInfo(
        name='filetype',
        type='string',
        description='type of the file the document chunk is from (application/pdf, application/msword, etc.)',
        ),
    AttributeInfo(
        name='languages',
        type='list',
        description='Document languages (en, fr, es, etc.)',
        ),
    AttributeInfo(
        name='page',
        type='integer',
        description='page number of the document chunk',
        ),
    AttributeInfo(
        name='published_date',
        type='string',
        description='date the file was published',
        ),
    AttributeInfo(
        name='section_title',
        type='string',
        description='Document section title',
        ),
    AttributeInfo(
        name='tags',
        type='list',
        description='tags associated with the document chunk',
        ),
]

# Initialize Pinecone and OpenAI
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=openai_api_key
)

filter_extraction_prompt = PromptTemplate(
    input_variables=["query"],
    template=(
        "Analyze the following query and extract relevant metadata filters. "
        "Return the filters as a JSON object.\n\nQuery: {query}"
    )
)

def extract_metadata_filters(query):
    response = llm.invoke(filter_extraction_prompt.format(query=query), response_format={ "type": "json_object" })
    filters = json.loads(response.content.strip())
    return filters

def perform_vector_search(query):
    return vectorstore.similarity_search(query, k=5)

def perform_keyword_search(metadata, filters):
    keyword_results = []
    for doc in metadata:
        if all(item in doc.items() for item in filters.items()):
            keyword_results.append(doc)
    return keyword_results

def perform_hybrid_search(query, filters):
    vector_results = perform_vector_search(query)
    metadata = [doc.metadata for doc in vector_results]
    keyword_results = perform_keyword_search(metadata, filters)
    combined_results = combine_results(vector_results, keyword_results)
    return combined_results

def combine_results(vector_results, keyword_results):
    combined = vector_results + keyword_results
    return combined

pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index('cassie-unstructured-advanced')
vectorstore = PineconeVectorStore(index, embeddings)

document_content_description = 'project and technical documents, project agreements, contracts, and other related documents.'
llm = ChatOpenAI(temperature=0, model_name="gpt-4o", openai_api_key=openai_api_key)

def hybrid_search(query):
    filters = extract_metadata_filters(query)
    results = perform_hybrid_search(query, filters)
    return results